{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "\n",
    "import altair as alt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import zscore\n",
    "from src.canonical_analysis.subspace_comm import CCARepeatedStim\n",
    "from src.gabor_analysis.gabor_fit import GaborFit\n",
    "from src.power_law.subtract_spont import SubtractSpontAnalyzer\n",
    "from src.spikeloader import SpikeLoader\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "path_loader = \"data/superstim_TX60_allsort.hdf5\"\n",
    "path_gabor = \"data/superstim_TX60_allsort_gabor.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "loader = SpikeLoader.from_hdf5(path_loader)\n",
    "gabor = GaborFit.from_hdf5(path_gabor)\n",
    "\n",
    "idx_spont = loader.idx_spont\n",
    "spks = zscore(loader.spks, axis=0)\n",
    "S_nospont = SubtractSpontAnalyzer(128).fit(spks, loader.idx_spont).transform(loader.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df_all: pd.DataFrame):\n",
    "    df_all = df_all.copy()\n",
    "    df_all[\"region\"] = \"brain\"\n",
    "\n",
    "    def checkerboard(item: pd.Series):\n",
    "        if ((item.x // 100) + (item.y // 100)) % 2 == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    df_all[\"group\"] = df_all.apply(checkerboard, axis=1).astype(\"category\")\n",
    "    return df_all\n",
    "\n",
    "\n",
    "regions = {\"brain\": (dict(group=0), dict(group=1))}\n",
    "\n",
    "cr = CCARepeatedStim(loader, gabor, prepare_df=prepare_df, regions=regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = loader.get_idx_rep()\n",
    "n_rep = rep.shape[0]\n",
    "rand = np.random.default_rng(42)\n",
    "# tr, te = train_test_split(np.arange(n_rep), train_size=0.8, random_state=42)\n",
    "sep = int(0.8 * n_rep)\n",
    "\n",
    "ns_train = [sep]\n",
    "with cr.set_spks_source(S_nospont):\n",
    "    df_classic = cr.calc_cr(ns_train, idx_train=rep[:sep, 0], idx_train2=rep[:sep, 0])\n",
    "    df_swap = cr.calc_cr(ns_train, idx_train=rep[:sep, 0], idx_train2=rep[:sep, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_scrambled = rep[rand.integers(low=0, high=n_rep, size=n_rep - sep), 0]\n",
    "\n",
    "\n",
    "def corr(df):\n",
    "    with cr.set_spks_source(S_nospont):\n",
    "        return cr.calc_innerprod_test(\n",
    "            df,\n",
    "            idxs_test={\n",
    "                \"rep1\": rep[sep:, 0],\n",
    "                \"rep2\": rep[sep:, 1],\n",
    "                \"scrambled\": idx_scrambled,\n",
    "                \"training_rep1\": rep[: n_rep - sep, 0],\n",
    "                \"training_rep2\": rep[: n_rep - sep, 1],\n",
    "            },\n",
    "            pairs=[\n",
    "                (\"rep1\", \"rep1\"),\n",
    "                (\"rep2\", \"rep2\"),\n",
    "                (\"rep2\", \"rep1\"),\n",
    "                (\"rep1\", \"rep2\"),\n",
    "                (\"rep1\", \"scrambled\"),\n",
    "                (\"training_rep1\", \"training_rep2\"),\n",
    "                (\"training_rep1\", \"training_rep1\"),\n",
    "            ],\n",
    "            normalize=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def gen_chart(data: pd.DataFrame) -> alt.Chart:\n",
    "    y = \"cov\" if \"cov\" in data.columns else \"corr\"\n",
    "    selection = alt.selection_multi(fields=[\"match\"], bind=\"legend\")\n",
    "    base = alt.Chart(data).encode(x=\"dimension\", y=y, color=\"match\",)\n",
    "\n",
    "    return (\n",
    "        base.mark_line()\n",
    "        .encode(\n",
    "            size=alt.condition(~selection, alt.value(1), alt.value(2)),\n",
    "            opacity=alt.condition(~selection, alt.value(0.4), alt.value(1)),\n",
    "            row=\"n:N\",\n",
    "        )\n",
    "        .properties(width=200, height=250)\n",
    "        .add_selection(selection)\n",
    "    )\n",
    "\n",
    "\n",
    "corr_classic, corr_swap = corr(df_classic), corr(df_swap)\n",
    "\n",
    "alt.hconcat(\n",
    "    gen_chart(corr_classic).properties(title=\"Classic\"),\n",
    "    gen_chart(corr_swap).properties(title=\"Swapped\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This is a plot of the correlation of canonical variates or projections\n",
    "between the activities of neuron groups 1 and 2, with different lines \n",
    "signifying different first/second repeat combinations.\n",
    "\n",
    "The name of each line is split by \\_ the first is always neuron group1\n",
    "and the second is always neuron group2\n",
    "\n",
    "- rep2_rep1: rep2 for neuron group 1 and rep1 for neuron group 2.\n",
    "\n",
    "The scrambled is just some random index from group1 with some random index from group2.\n",
    "Weâ€™re pairing unrelated images and we expect a correlation of 0.\n",
    "The training is using the training dataset to establish an upper bound.\n",
    "\n",
    "\n",
    "### Training\n",
    "80:20 train/test split without randomization.\n",
    "- Classic: Group 1 and 2: stims from repeat 1.\n",
    "- Swapped: Group 1: stims from repeat 1. Group 2: stims from repeat 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "# sns.FacetGrid(\n",
    "#     data=df_transformed[df_transformed[\"stim\"].isin(rand.integers(low=0, high=n_rep, size=15))],\n",
    "#     col=\"stim\",\n",
    "#     col_wrap=5,\n",
    "# ).map(\n",
    "#     sns.regplot, \"rep1\", \"rep2\", scatter_kws={\"s\": 1, \"alpha\": 0.5},\n",
    "# )\n",
    "# sns.regplot(\n",
    "#     \"rep1\",\n",
    "#     \"rep2\",\n",
    "#     data=df_transformed[df_transformed.stim == 0],\n",
    "#     ax=ax,\n",
    "#     scatter_kws={\"s\": 1, \"alpha\": 0.5},\n",
    "# )\n",
    "# ax.set_aspect(\"equal\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
